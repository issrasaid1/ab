<!doctype html>

<html>
  <head>
    <title>A/B Testing</title>
    <link rel="stylesheet" href="index.css">
    <!-- TODO: add additional links here! e.g. fonts, icons, more stylesheets, etc. -->
    <meta content="width=device-width, initial-scale=1" name="viewport" />
  </head>

  <body>
    <body style="background-color:lightgray;">

    <h1>A/B Testing</h1>

  <h5 style="font-family:'Helvetica'; font-style: italic; text-align:center">  For this project, I performed an A/B test and statistical analysis to gather insight into two different UI designs. <br>This is the link to the deployed app, (<a href="https://pacific-mountain-57020.herokuapp.com">AB test</a>), which opens interface A fifty percent of the time and B the other fifty percent of the time. <br>For this project, I used two metrics to evaluate the effect of the changes in the interface: time to completion and return rate.</h5>
  <h2 style="font-family:'Helvetica';text-align:center"> Interface A </h2>
  <img src="interfaceA.png" class="center" style="width:75%">
  <p style="font-family:'Helvetica';text-align:center"> For interface A, I added bold text to the plant descriptions and prices. I did this to help with user readibility. </p>
    <h2 style="font-family:'Helvetica';text-align:center"> Interface B </h2>
  <img src="interfaceB.png" class="center" style="width:75%">
  <p style="font-family:'Helvetica';text-align:center"> For interface A, I increased the size of the plant images. I did this to create a cleaner design overall with evenly spaced margin between each photo and the add to cart button. </p>

  <h2 style="font-family:'Helvetica';text-align:center"> Time to completion  </h2>
    <p style="font-family:'Helvetica';text-align:center;font-style: italic;"> Time to completion can be defined as the time it took for the user to complete the task, which was to add at least 150 dollars worth of plants into the cart.</p>
    <p style="font-family:'Helvetica';text-align:center"><b> Null Hypothesis: </b>There is no significant difference between the time it takes to order cacti with interface A and interface B because the changes made to the interface were relatively minor. Thus, the time to completion for A will be equal to B.</p>
      <br>  <p style="font-family:'Helvetica';text-align:center"> <b>Alternative Hypothesis: </b>  The time to completion for A will be greater than that of B because the prices (and plant descriptions) are bolded in interface A; therefore, it will be easier (because of readability) for the user to complete the task. </p>

      <h2 style="font-family:'Helvetica';text-align:center"> Return rate  </h2>
      <p style="font-family:'Helvetica';text-align:center;font-style: italic;"> Return rate can be defined as the number of times a user returned to the home page after clicking checkout. </p>
      <p style="font-family:'Helvetica';text-align:center" ><b> Null Hypothesis: </b> There is no significant difference between return rate for cacti with interface A and interface B because the changes made to the interface were relatively minor. Thus, the return rate for A will be equal to B. <br></p>
        <p style="font-family:'Helvetica';text-align:center" >
        <b>Alternative Hypothesis: </b> There is a significant difference between the number of times a user returned to the page on interface A and interface B because there is a difference in interface. For interface B, the plant descriptions and prices are bolded; whereas for interface B, the images of the plants are larger. Therefore, the return rate of A will not be equal to B. </p>

  <h2 style="font-family:'Helvetica';text-align:center"> Data collection process </h2>
  <p style="font-family:'Helvetica';text-align:center">
     I conducted data collection in order to test my hypotheses. I, first, distributed  the link to the interface to a multitude of users to complete the task. I was able to extract the time logs for when the user interacted with the interface: from whenever they clicked a button to either add to cart or go to cart,  to when (or if) they returned to the home page. This data was logged into an excel sheet. Next, I hand calculated time to completion for each user and noted whether they were viewing interface A or B. I also recorded whether or not the user returned to the home page. In order to analyze this raw data to test my hypotheses, I created a python script to run the statistical tests needed. These tests were used in order to calculate the p values for each metric. To find the p value for time to completion and return rate I used a two-tailed t test and chi squared test, respectively. </p>

    <h2 style="font-family:'Helvetica';text-align:center"> Infographic: Statistical conclusions </h2>


  <img src="infoabactual.png" class="center">
    <p style="font-family:'Helvetica';text-align:center"> In both cases, the p-value calculated is greater than 0.05; therefore, we fail to reject the null hypothesis in both cases. This means that for both time to completion and return rate, my results are statistically insignificant. In other words, there is a doubt as to whether the alternative hypothesis will repeat itself in other trials or situations.  From these results, we must fail to reject there was no difference in time to completion between Version A and Version B of my pages. These results also tell us that we must fail to reject that there was no difference in return rate between Version A and Version B of my pages. </p>

    <h2 style="font-family:'Helvetica';text-align:center"> Takeaways </h2>
      <p style="font-family:'Helvetica';text-align:center">
    There are limitations that may have affected the results of my test. For one, the data analysis may have been skewed since interface A had 15 users, while interface B had only 10 users. Also, the changes I made to interface A and B were relatively minor. Therefore, it may not have had a significant impact on the user's experience with both interfaces. Furthermore, the test users mass-completed this task of adding plants to the cart
    for multiple other students also conducting similar A/B tests. It is possible that the users, overall, were able to complete this task at the same rate for both interface A and B because they were well-familiarized with the general interface (since many students' changes to interface A and B were not too drastic).</p>
  <p style="font-family:'Helvetica';text-align:center">
<br>Through this project I was able to reflect more about design choices and how they affect user experience. These design choices can have a significant impact on the user's ability to navigate the interface. However, since my AB test failed to reject the null for both metrics, I am unable to associate this analysis with my results (since the results proved inconclusive).</p>

  </body>
</html>
